{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47335edf-247e-4fa6-9238-b0a31f3aadd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------\n",
    "# filename feature_engineering_pipeline_train_inference\n",
    "# author Partha Deka\n",
    "# revision 1.0\n",
    "# revision history 1.0 - initial script"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83ae09f9-0639-4e0f-909a-03230f153b4c",
   "metadata": {},
   "source": [
    "# Import all dependencies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8591abcc-a9eb-4445-a617-ece6c7d9d588",
   "metadata": {},
   "source": [
    "# Timeseries Forecasting: `End-End Pipeline Code`\n",
    "- The intial code for time series model training and prediction is based on the associated with `Chapter 10`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cc8a8732-6056-4055-8b34-c0de8337b70a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 1.6107611013565681\n",
      "              Actual  Predicted\n",
      "Date                           \n",
      "2020-03-21  2.398436   1.065399\n",
      "2020-03-22  0.264023   2.270394\n",
      "2020-03-23 -0.002856   0.220992\n",
      "2020-03-24 -0.639781   1.801060\n",
      "2020-03-25 -0.313801  -0.360834\n"
     ]
    }
   ],
   "source": [
    "# Custom transformer for creating lagged features\n",
    "class LagFeatureTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, lags=3):\n",
    "        self.lags = lags\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        df = pd.DataFrame(X.copy())\n",
    "        for lag in range(1, self.lags + 1):\n",
    "            df[f'lag_{lag}'] = df['Value'].shift(lag)\n",
    "        df.dropna(inplace=True)\n",
    "        return df\n",
    "\n",
    "# Create a synthetic time series dataset\n",
    "date_range = pd.date_range(start='1/1/2020', periods=100, freq='D')\n",
    "data = pd.DataFrame({'Date': date_range, 'Value': np.random.randn(100).cumsum()})\n",
    "data.set_index('Date', inplace=True)\n",
    "\n",
    "# Create lag features and corresponding target\n",
    "lagged_data = LagFeatureTransformer(lags=3).transform(data)\n",
    "X = lagged_data.drop(columns=['Value'])  # Features: lagged values\n",
    "y = lagged_data['Value']  # Target: original values shifted by lag\n",
    "\n",
    "# Train-test split  - set a seed for reproducibility random_state=42\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False, random_state = 0)\n",
    "\n",
    "# Define the pipeline with scaling and XGBoost model\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler()),                    # Feature scaling\n",
    "    ('model', XGBRegressor(objective='reg:squarederror'))  # XGBoost for regression\n",
    "])\n",
    "\n",
    "# Train the pipeline\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(f'Mean Squared Error: {mse}')\n",
    "\n",
    "# Display the predicted vs actual values\n",
    "result = pd.DataFrame({'Actual': y_test, 'Predicted': y_pred}, index=X_test.index)\n",
    "print(result.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58c7468e-f1b1-4638-9d42-76bf590f5c1e",
   "metadata": {},
   "source": [
    "# Housing Prediction with all Feature Engineering: `End-End Pipeline Code`\n",
    "- The intial code with feature egineering steps is based on `Chapter 7`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aa4eca60-6a46-4ab6-a789-6982716b27ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 1130202899.0655065\n",
      "      Actual      Predicted\n",
      "892   154500  142317.156250\n",
      "1105  325000  364155.031250\n",
      "413   115000   93371.398438\n",
      "522   159000  135780.375000\n",
      "1036  315500  266444.375000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Custom transformer for handling missing values in categorical variables\n",
    "class MissingValueImputer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, for_missing_string, for_frequent_category):\n",
    "        self.for_missing_string = for_missing_string\n",
    "        self.for_frequent_category = for_frequent_category\n",
    "        self.frequent_categories = {}\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        # Store the most frequent category for variables with few missing observations\n",
    "        for var in self.for_frequent_category:\n",
    "            self.frequent_categories[var] = X[var].mode()[0]\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        # Replace missing values with \"Missing\" for specific variables\n",
    "        X[self.for_missing_string] = X[self.for_missing_string].fillna('Missing')\n",
    "        # Replace missing values with the most frequent category for specific variables\n",
    "        for var in self.for_frequent_category:\n",
    "            X[var] = X[var].fillna(self.frequent_categories[var])\n",
    "        return X\n",
    "\n",
    "# Load the dataset (Assuming the dataset is available)\n",
    "data = pd.read_csv(\"house_pricing.csv\")\n",
    "\n",
    "# Define feature columns\n",
    "numeric_features = ['LotArea', 'YearBuilt', '1stFlrSF', '2ndFlrSF', 'GrLivArea']\n",
    "categorical_features = ['Neighborhood', 'HouseStyle', 'GarageType', 'SaleCondition']\n",
    "\n",
    "# Handle missing categorical variables\n",
    "cat_vars_with_na = [var for var in categorical_features if data[var].isnull().sum() > 0]\n",
    "for_missing_string = [var for var in cat_vars_with_na if data[var].isnull().mean() > 0.1]\n",
    "for_frequent_category = [var for var in cat_vars_with_na if data[var].isnull().mean() < 0.1]\n",
    "\n",
    "# Target column\n",
    "target = 'SalePrice'\n",
    "\n",
    "# Split the data into features and target\n",
    "X = data.drop(columns=[target, 'Id'])\n",
    "y = data[target]\n",
    "\n",
    "# Split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define preprocessing steps for numeric and categorical features\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='mean')),  # Handle missing values\n",
    "    ('scaler', StandardScaler())                 # Scale features\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),  # Handle missing categorical values\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))     # One-hot encode categorical features\n",
    "])\n",
    "\n",
    "# Combine both numeric and categorical preprocessing, along with custom missing value handling\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ])\n",
    "\n",
    "# Define the complete pipeline\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('missing_imputer', MissingValueImputer(for_missing_string, for_frequent_category)),  # Custom missing value handling\n",
    "    ('preprocessor', preprocessor),               # Preprocessing step\n",
    "    ('model', XGBRegressor(objective='reg:squarederror'))  # XGBoost regression model\n",
    "])\n",
    "\n",
    "# Train the pipeline\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(f'Mean Squared Error: {mse}')\n",
    "\n",
    "# Display the predicted vs actual values\n",
    "result = pd.DataFrame({'Actual': y_test, 'Predicted': y_pred}, index=X_test.index)\n",
    "print(result.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68053088-4e9c-4beb-b816-b303a51a5530",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
